from diffusers import StableDiffusionPipeline
import torch

# Verificar si CUDA est치 disponible
print("쮺UDA disponible?", torch.cuda.is_available())
if torch.cuda.is_available():
    print("Nombre de GPU:", torch.cuda.get_device_name(0))
else:
    print("Est치s usando CPU 游땩")

# Cargar el modelo preentrenado desde un directorio de cach칠 local
pipeline = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    cache_dir="./modelo_diffusion"
).to("cuda" if torch.cuda.is_available() else "cpu")

# Definir el prompt para la generaci칩n de la imagen
prompt = "Un perro y un gato"

# Generar la imagen con menos pasos para mayor velocidad
image = pipeline(
    prompt,
    height=384,  # tama침o m치s peque침o que 512x512
    width=384,
    num_inference_steps=20  # menos pasos = m치s r치pido
).images[0]

# Guardar la imagen
image.save("imagen_generada.png")

# Mostrar la imagen
image.show()
